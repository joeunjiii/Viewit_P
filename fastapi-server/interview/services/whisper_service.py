# ëª¨ë¸ë§Œ ë¡œë”©
import whisper
import os
import subprocess
from dotenv import load_dotenv
import io
import torch
import torch
# .env íŒŒì¼ ì½ê¸°
load_dotenv()
FFMPEG_BIN_PATH = os.getenv("FFMPEG_BIN_PATH")
if not FFMPEG_BIN_PATH:
    raise RuntimeError("FFMPEG_BIN_PATH í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")


device = "cuda" if torch.cuda.is_available() else "cpu"
if device == "cuda":
    print("ğŸ”Š Whisper ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘... (GPU ì‚¬ìš©)")
else:
    print("ğŸ”Š Whisper ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘... (CPU ì‚¬ìš©)")

model = whisper.load_model("base").to(device)
print("âœ… Whisper ëª¨ë¸ ë¡œë”© ì™„ë£Œ (device:", device, ")")
print(torch.cuda.memory_allocated() / 1024 ** 2, "MB")

def convert_webm_to_wav(webm_path: str, wav_path: str):
    cmd = [
        FFMPEG_BIN_PATH, "-y",
        "-i", webm_path,
        "-acodec", "pcm_s16le",
        "-ar", "16000",
        "-ac", "1",
        wav_path
    ]
    subprocess.run(cmd, check=True)

def stt_from_webm(webm_path: str):
    # 1. webm â†’ wav ë³€í™˜
    wav_path = webm_path.rsplit(".", 1)[0] + ".wav"
    convert_webm_to_wav(webm_path, wav_path)
    # 2. Whisperë¡œ STT
    result = model.transcribe(wav_path, language="ko")
    return result["text"]
