import React, { useEffect, useRef, useState, useCallback } from "react";
import MicRecorder from "./asset/Mic/MicRecorder";
import { requestNextTTSQuestion, requestTTS } from "./api/tts";
import Timer from "./asset/Timer";

const PHASE = {
  READY: "ready",
  TTS: "tts",
  WAITING: "wait",
  RECORDING: "recording",
  UPLOADING: "uploading",
  COMPLETE: "complete",
};

function InterviewSessionManager({
  waitTime = 3,
  answerDuration = 10,
  allowRetry = true,
  onStatusChange,
  onTimeUpdate,
  onAnswerComplete,
}) {
  const [phase, setPhase] = useState(PHASE.READY);
  const [question, setQuestion] = useState(null);
  const [remainingTime, setRemainingTime] = useState(0);
  const timerRef = useRef(null);
  const recorderRef = useRef(null);
  const audioRef = useRef(null);
  const lastPlayedAudioUrl = useRef(null);
  const isPlaying = useRef(false);

  const updatePhase = useCallback(
    (p) => {
      setPhase(p);
      onStatusChange?.(p);
    },
    [onStatusChange]
  );

  const updateTime = useCallback(
    (t) => {
      setRemainingTime(t);
      onTimeUpdate?.(t);
    },
    [onTimeUpdate]
  );

  const startCountdown = useCallback(
    (seconds, onFinish) => {
      clearInterval(timerRef.current);
      updateTime(seconds);
      timerRef.current = setInterval(() => {
        updateTime((prev) => {
          const next = prev - 1;
          if (next <= 0) {
            clearInterval(timerRef.current);
            onFinish();
            return 0;
          }
          return next;
        });
      }, 1000);
    },
    [updateTime]
  );

  const stopRecording = useCallback(() => {
    updatePhase(PHASE.UPLOADING);
    recorderRef.current.stop();
  }, [updatePhase]);

  const fetchNextQuestion = useCallback(async () => {
    let result;
    try {
      if (!question) {
        const audioUrl = await requestTTS();
        if (audioUrl) {
          result = { audioUrl, question: "ìžê¸°ì†Œê°œ ë¶€íƒë“œë¦½ë‹ˆë‹¤." };
        }
      } else {
        result = await requestNextTTSQuestion();
      }

      // âœ… resultì™€ audioUrlì´ ëª¨ë‘ ìžˆì–´ì•¼ TTS ë‹¨ê³„ë¡œ ì§„í–‰
      if (result && result.audioUrl) {
        setQuestion(result);
        updatePhase(PHASE.TTS);
      } else {
        console.warn("âŒ ì§ˆë¬¸ ë˜ëŠ” ì˜¤ë””ì˜¤ URL ëˆ„ë½ - WAITING ìœ ì§€");
        updatePhase(PHASE.WAITING);
        updateTime(waitTime);
      }
    } catch (error) {
      console.error("âŒ fetchNextQuestion ì˜ˆì™¸ ë°œìƒ:", error);
      updatePhase(PHASE.WAITING);
      updateTime(waitTime);
    }
  }, [updatePhase, updateTime, waitTime]);

  // TTS ì˜¤ë””ì˜¤ ìž¬ìƒì„ ìœ„í•œ ë³„ë„ useEffect
  useEffect(() => {
    if (phase === PHASE.TTS && question?.audioUrl && !isPlaying.current) {
      console.log("ðŸŽµ TTS ì˜¤ë””ì˜¤ ìž¬ìƒ ì‹œìž‘:", question.audioUrl);
      isPlaying.current = true;

      // ê¸°ì¡´ ì˜¤ë””ì˜¤ ì •ë¦¬
      if (audioRef.current) {
        audioRef.current.pause();
        audioRef.current = null;
      }

      const audio = new Audio("http://localhost:8000" + question.audioUrl);
      audioRef.current = audio;
      audio.play();
      audio.onended = () => {
        console.log("ðŸŽµ TTS ì˜¤ë””ì˜¤ ìž¬ìƒ ì™„ë£Œ, WAITINGìœ¼ë¡œ ì „í™˜");
        isPlaying.current = false;
        updatePhase(PHASE.WAITING);
      };
    }
  }, [phase, question?.audioUrl, updatePhase]);

  // WAITING íŽ˜ì´ì¦ˆì—ì„œ íƒ€ì´ë¨¸ ì‹œìž‘
  useEffect(() => {
    if (phase === PHASE.WAITING) {
      console.log("â° WAITING íŽ˜ì´ì¦ˆ - íƒ€ì´ë¨¸ ì‹œìž‘:", waitTime);
      startCountdown(waitTime, () => updatePhase(PHASE.RECORDING));
    }
  }, [phase, waitTime, startCountdown, updatePhase]);

  const handleRecordingComplete = async (blob) => {
    const formData = new FormData();
    formData.append("audio", blob, "answer.webm");
    try {
      const res = await fetch("http://localhost:8000/stt", {
        method: "POST",
        body: formData,
      });
      const data = await res.json();
      onAnswerComplete?.(data.text);
    } catch (err) {
      console.error("STT ì˜¤ë¥˜:", err);
    }
    updatePhase(PHASE.COMPLETE);
  };

  useEffect(() => {
    fetchNextQuestion();
    return () => clearInterval(timerRef.current);
  }, [fetchNextQuestion]);

  return (
    <div className="interview-session">
      <MicRecorder
        ref={recorderRef}
        isRecording={phase === PHASE.RECORDING}
        onStop={handleRecordingComplete}
      />

      {phase === PHASE.TTS}

      {phase === PHASE.WAITING && (
        <div className="timer-area">
          <Timer
            key={phase}
            duration={remainingTime}
            autoStart={true}
            label="ëŒ€ê¸°ì‹œê°„"
          />
          <div style={{ display: "flex", gap: "10px", marginTop: "20px" }}>
            {allowRetry && (
              <button
                className="replay-button"
                onClick={() => {
                  updateTime(waitTime);
                  updatePhase(PHASE.WAITING);
                }}
              >
                ë‹¤ì‹œ ë‹µë³€í•˜ê¸°
              </button>
            )}
          </div>
        </div>
      )}
    </div>
  );
}

export default InterviewSessionManager;
