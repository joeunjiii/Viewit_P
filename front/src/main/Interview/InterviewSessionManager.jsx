import React, { useState, useRef, useEffect } from "react";
import MicRecorder from "./asset/Mic/MicRecorder";
import { initSession, nextQuestion } from "./api/interview";
import { requestSpeechToText } from "./api/stt";
//import { requestNextTTSQuestion, requestTTS } from "./api/tts";
import Timer from "./asset/Timer";

const PHASE = {
  IDLE: "idle",
  READY: "ready",
  TTS: "tts",
  WAITING: "wait",
  RECORDING: "recording",
  UPLOADING: "uploading",
  COMPLETE: "complete",
  END: "end",
  INTRO_TTS: "intro_tts",
  FINAL_TTS: "final_tts",
};

function InterviewSessionManager({
  sessionId,
  jobRole,
  waitTime = 3,
  allowRetry = true,
  onStatusChange,
  onTimeUpdate,
  onAnswerComplete,
  onNewQuestion,
}) {
  const [phase, setPhase] = useState(PHASE.READY);
  const [question, setQuestion] = useState(null);
  const [remainingTime, setRemainingTime] = useState(0);
  const [sttResult, setSttResult] = useState(null);
  const [fixedQuestionIdx, setFixedQuestionIdx] = useState(0);
  const timerRef = useRef(null);
  const recorderRef = useRef(null);
  const audioRef = useRef(null);

  // ì„¸ì…˜ ì´ˆê¸°í™”
  useEffect(() => {
    console.log("InterviewSessionManager mounted");
    console.log("initSession fired");
    initSession(sessionId, jobRole)
      .then((res) => {
        const { question: q, audio_url } = res.data;
        setQuestion({ question: q, audio_url, done: false });
        onNewQuestion?.(q);
        setPhase(PHASE.TTS);
      })
      .catch((err) => console.error("init_session ì‹¤íŒ¨", err));
  }, [sessionId, jobRole, onNewQuestion]);

  // TTS ì¬ìƒ
  useEffect(() => {
    if (phase === PHASE.TTS && question?.audio_url) {
      if (audioRef.current) {
        audioRef.current.pause();
        audioRef.current = null;
      }
      const url = question.audio_url.startsWith("http")
        ? question.audio_url
        : "http://localhost:8000" + question.audio_url;
      const audio = new Audio(url);
      audioRef.current = audio;
      audio.onended = () => setPhase(PHASE.WAITING);
      audio.play().catch(() => setPhase(PHASE.WAITING));
    }
  }, [phase, question]);

  // íƒ€ì´ë¨¸ (ì§ˆë¬¸ í›„ ëŒ€ê¸°)
  useEffect(() => {
    onStatusChange?.(phase);
    clearInterval(timerRef.current);

    if (phase === PHASE.WAITING) {
      setRemainingTime(waitTime);
      onTimeUpdate?.(waitTime);
      timerRef.current = setInterval(() => {
        setRemainingTime((prev) => {
          onTimeUpdate?.(prev - 1);
          if (prev <= 1) {
            clearInterval(timerRef.current);
            setPhase(PHASE.RECORDING);
            return 0;
          }
          return prev - 1;
        });
      }, 1000);
    }

    // answerDuration íƒ€ì´ë¨¸ ì™„ì „ ì œê±°

    return () => clearInterval(timerRef.current);
  }, [phase, waitTime, onStatusChange, onTimeUpdate]);

  // ğŸ”¥ ì¹¨ë¬µ ê°ì§€
  const handleSilence = (duration) => {
    // duration: ì¹¨ë¬µ ì§€ì† ì‹œê°„(ì´ˆ), 5ì´ˆ ì´ìƒì´ë©´ ìë™ ì œì¶œ
    if (phase === PHASE.RECORDING && duration >= 5) {
      recorderRef.current?.stop();
      setPhase(PHASE.UPLOADING);
    }
  };

  // ë…¹ìŒ ì™„ë£Œ â†’ STT
  const handleRecordingComplete = async (blob) => {
    setPhase(PHASE.UPLOADING);
    try {
      const data = await requestSpeechToText(blob);
      setSttResult(data.text);
      setPhase(PHASE.COMPLETE);
    } catch (err) {
      console.error("STT ì˜¤ë¥˜:", err);
    }
  };

  // ë‹µë³€ ì™„ë£Œ â†’ ë‹¤ìŒ ì§ˆë¬¸
  useEffect(() => {
    console.log("InterviewSessionManager mounted");
    console.log("initSession fired");

    if (phase !== PHASE.COMPLETE || !sttResult) return;

    onAnswerComplete?.(sttResult);

    nextQuestion(sessionId, sttResult)
      .then((res) => {
        const { question: q, audio_url, done } = res.data;
        setQuestion({ question: q, audio_url, done });
        onNewQuestion?.(q);
        setPhase(done ? PHASE.WAITING : PHASE.TTS);
      })
      .catch((err) => console.error("next_question ì‹¤íŒ¨", err))
      .finally(() => setSttResult(null));
  }, [phase, sttResult, sessionId, onNewQuestion, onAnswerComplete]);

  const handleRetry = () => {
    setRemainingTime(waitTime);
    setPhase(PHASE.WAITING);
  };

  if (phase === PHASE.READY) {
    return <div className="loading">ëª¨ì˜ ë©´ì ‘ ì§ˆë¬¸ ìƒì„±ì¤‘...</div>;
  }

  return (
    <div className="interview-session">
      <MicRecorder
        ref={recorderRef}
        isRecording={phase === PHASE.RECORDING}
        onStop={handleRecordingComplete}
        onSilence={handleSilence} // ì¹¨ë¬µ ê°ì§€ ì½œë°± ì¶”ê°€
      />
      {phase === PHASE.WAITING && (
        <div className="timer-area">
          <Timer duration={remainingTime} autoStart label="ëŒ€ê¸°ì‹œê°„" />
          {allowRetry && (
            <button className="replay-button" onClick={handleRetry}>
              ë‹¤ì‹œ ë‹µë³€í•˜ê¸°
            </button>
          )}
        </div>
      )}
    </div>
  );
}

export default InterviewSessionManager;
