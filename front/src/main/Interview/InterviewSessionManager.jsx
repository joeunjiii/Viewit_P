import React, { useState, useRef, useEffect } from "react";
import MicRecorder from "./asset/Mic/MicRecorder";
import { nextQuestion, saveInterview, endSession } from "./api/interview";  // â˜… ì¢…ë£Œ API í˜¸ì¶œ import
import { requestSpeechToText } from "./api/stt";
import { useNavigate } from "react-router-dom";
import UserAnswerDisplay from "./asset/UserAnswerDisplay";
const PHASE = {
  TTS: "tts",           // TTS ì¬ìƒ ì¤‘
  WAITING: "wait",      // ë…¹ìŒ ì „ ëŒ€ê¸° ì¤‘
  RECORDING: "recording",// ë…¹ìŒ ì¤‘
  UPLOADING: "uploading",// ë…¹ìŒ ë°ì´í„° ì—…ë¡œë“œ ì¤‘
  COMPLETE: "complete",  // STT ì™„ë£Œ ë° ì‘ë‹µ ëŒ€ê¸° ìƒíƒœ
};

function InterviewSessionManager({
  sessionId,
  waitTime = 3,
  // allowRetry = true,
  initialQuestion,
  onStatusChange,
  onTimeUpdate,
  onNewQuestion,
  onAnswerComplete,
  onCaptionUpdate,
  jdText,
  pdfText,
  onUserAnswer, // ì‚¬ìš©ì ë‹µë³€ ì „ë‹¬ ì½œë°±
}) {
  const [phase, setPhase] = useState(PHASE.TTS);
  const [answer, setAnswer] = useState("");
  const [question, setQuestion] = useState(initialQuestion);
  const [remainingTime, setRemainingTime] = useState(0);
  const [sttResult, setSttResult] = useState(null);

 

  // ì´ˆê¸° ì§ˆë¬¸ ì„¸íŒ…: initialQuestionì´ ë°”ë€Œë©´ ì§ˆë¬¸ê³¼ ë‹¨ê³„ ì´ˆê¸°í™”
  const timerRef = useRef(null);       // íƒ€ì´ë¨¸ ê´€ë¦¬ìš© ref
  const recorderRef = useRef(null);    // ë…¹ìŒê¸° ê´€ë¦¬ìš© ref
  const audioRef = useRef(null);       // TTS ì˜¤ë””ì˜¤ ê´€ë¦¬ìš© ref
  const navigate = useNavigate();      // í˜ì´ì§€ ì´ë™ìš© í›…
  const sttInProgressRef = useRef(false);
  // ì´ˆê¸° ì§ˆë¬¸ ì„¸íŒ…
  useEffect(() => {
    setQuestion(initialQuestion);
    setPhase(PHASE.TTS);
  }, [initialQuestion]);

  useEffect(() => {
    if (!onStatusChange) return;
    // ë Œë” ì§í›„ ì•ˆì „í•˜ê²Œ ë¶€ëª¨ ìƒíƒœ ë³€ê²½
    const id = requestAnimationFrame(() => onStatusChange(phase));
    return () => cancelAnimationFrame(id);
  }, [phase, onStatusChange]);

  useEffect(() => {
    if (phase === PHASE.TTS && question?.question) {
      onCaptionUpdate?.(`ë©´ì ‘ê´€: ${question.question}`);
    }

    if (phase === PHASE.TTS && question?.audio_url) {
      const url = question.audio_url.startsWith("http")
          ? question.audio_url
          : "http://localhost:8000" + question.audio_url;

      const audio = new Audio(url);
      audioRef.current = audio;
      audio.onended = () => {
        console.log("[TTS] ì˜¤ë””ì˜¤ ì¬ìƒ ì¢…ë£Œ, phase WAITING ì „í™˜");
        setPhase(PHASE.WAITING);
      };
      audio
        .play()
        .then(() => console.log("[TTS] ì˜¤ë””ì˜¤ ì¬ìƒ ì‹œì‘!"))
        .catch((err) => {
          console.error("[TTS] ì˜¤ë””ì˜¤ play ì—ëŸ¬:", err);
          setPhase(PHASE.WAITING);
        });
    }
  }, [phase, question, onCaptionUpdate]);


  // ë…¹ìŒ ì „ ëŒ€ê¸° ë° ë…¹ìŒ ì‹œì‘
  useEffect(() => {
    clearInterval(timerRef.current);

    if (phase === PHASE.WAITING) {
      setRemainingTime(waitTime);
      onTimeUpdate?.(waitTime);

      // 1ì´ˆ ê°„ê²©ìœ¼ë¡œ ì¹´ìš´íŠ¸ë‹¤ìš´, 0 ë˜ë©´ ë…¹ìŒ ì‹œì‘
      timerRef.current = setInterval(() => {
        setRemainingTime((prev) => {
          onTimeUpdate?.(prev - 1);
          if (prev <= 1) {
            clearInterval(timerRef.current);
            setPhase(PHASE.RECORDING);
            return 0;
          }
          return prev - 1;
        });
      }, 1000);
    }

    // ë…¹ìŒ ë‹¨ê³„ì—ì„œëŠ” ë…¹ìŒ ì‹œì‘
    if (phase === PHASE.RECORDING) {
      recorderRef.current?.start?.();
    }

    // ì»´í¬ë„ŒíŠ¸ ì–¸ë§ˆìš´íŠ¸ ë˜ëŠ” phase ë³€ê²½ ì‹œ íƒ€ì´ë¨¸ í´ë¦¬ì–´
    return () => clearInterval(timerRef.current);
  }, [phase, waitTime, onTimeUpdate]);

  // ë…¹ìŒ ì™„ë£Œ ì‹œ í˜¸ì¶œ: STT API í˜¸ì¶œ ë° ê²°ê³¼ ì²˜ë¦¬
  const handleRecordingComplete = async (blob) => {
    if (sttInProgressRef.current) {
      console.warn("STT ì¤‘ë³µ í˜¸ì¶œ ì°¨ë‹¨!");
      return;
    }
    sttInProgressRef.current = true; // ì²« ì§„ì…ì—ë§Œ true

    console.log("ğŸ¤ handleRecordingComplete í˜¸ì¶œë¨!", blob);
    setPhase(PHASE.UPLOADING);
    try {
      const data = await requestSpeechToText(blob);
      setSttResult(data.text);
      // onCaptionUpdate?.(`ì´ìš©ì: ${data.text}`);
      // ì‚¬ìš©ì ë‹µë³€ì„ ë³„ë„ ì½œë°±ìœ¼ë¡œ ì „ë‹¬
      onUserAnswer?.(data.text);
      setPhase(PHASE.COMPLETE);
    } catch (err) {
      console.error("STT ì˜¤ë¥˜:", err);
    }
  };

  // phaseê°€ RECORDINGì´ ë  ë•Œë§ˆë‹¤ flagë¥¼ ì´ˆê¸°í™”
  useEffect(() => {
    if (phase === PHASE.RECORDING) {
      sttInProgressRef.current = false;
    }
  }, [phase]);

  
  // ë‹µë³€ ì €ì¥ & ë‹¤ìŒ ì§ˆë¬¸ ë˜ëŠ” ìë™ ì´í‰

  // ë‹µë³€ ì €ì¥ & ë‹¤ìŒ ì§ˆë¬¸ ìš”ì²­ ë˜ëŠ” ë©´ì ‘ ì¢…ë£Œ ì²˜ë¦¬
  useEffect(() => {
    if (phase === PHASE.COMPLETE && sttResult) {
      console.log("ğŸ”¥ nextQuestion API ìš”ì²­ ì‹œì‘:", { phase, sttResult });
      (async () => {
        try {
          // 1. ë‹µë³€ ì €ì¥ API í˜¸ì¶œ
          await saveInterview({
            sessionId,
            questionText: question?.question || "",
            answerText: sttResult,
            filterWord: "",
            answerFeedback: "",
          });
          console.log("âœ… ë‹µë³€ ì €ì¥ ì„±ê³µ!");
        } catch (e) {
          alert("ì €ì¥ ì‹¤íŒ¨: " + e.message);
          return;
        }

        try {
          // 2. ë‹¤ìŒ ì§ˆë¬¸ ë˜ëŠ” ì¢…ë£Œ ì—¬ë¶€ íŒë‹¨ API í˜¸ì¶œ
          const res = await nextQuestion(sessionId, sttResult, jdText, pdfText);
          console.log("âœ… nextQuestion API ì‘ë‹µ:", res);
          const data = res.data;

          // 3. done === true ì´ë©´ ë©´ì ‘ ì¢…ë£Œ ì²˜ë¦¬ (ì¢…ë£Œ API í˜¸ì¶œ ë° í”¼ë“œë°± í˜ì´ì§€ ì´ë™)
          if (data.done === true) {
            alert("ë©´ì ‘ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.\n" + (data.message || ""));
            await endSession(sessionId);  // ì¢…ë£Œ API í˜¸ì¶œ
            navigate(`/feedback/${sessionId}`); // í”¼ë“œë°± ê²°ê³¼ í˜ì´ì§€ë¡œ ì´ë™
            onAnswerComplete?.(sttResult);
            return; // ì´í›„ ë¡œì§ ì¤‘ë‹¨
          }

          // 4. doneì´ falseë©´ ë‹¤ìŒ ì§ˆë¬¸ ì„¸íŒ… ë° TTS ì¬ìƒ ë‹¨ê³„ë¡œ ì „í™˜
          const { question: q, audio_url, done } = data;
          setQuestion({ question: q, audio_url, done });
          onNewQuestion?.(q);
          setPhase(PHASE.TTS);
        } catch (err) {
          alert("ë‹¤ìŒ ì§ˆë¬¸ í˜¸ì¶œ ì‹¤íŒ¨: " + err.message);
        }

        // ìƒíƒœ ì´ˆê¸°í™”
        setSttResult(null);
        onAnswerComplete?.(sttResult);
      })();
    }
  }, [
    phase,
    sttResult,
    sessionId,
    question,
    onAnswerComplete,
    onNewQuestion,
    navigate,
    jdText,
    pdfText,
  ]);

  return (
    <div className="interview-session">
      <UserAnswerDisplay
        status={phase}
        answer={answer}
        isVisible={true}
        title="ë‚´ ë‹µë³€"
        placeholder="ë‹µë³€ì„ ê¸°ë‹¤ë¦¬ëŠ” ì¤‘..."
      />
      <MicRecorder
        ref={recorderRef}
        isRecording={phase === PHASE.RECORDING}
        onStop={handleRecordingComplete}
      />
      <MicRecorder
        ref={recorderRef}
        isRecording={phase === PHASE.RECORDING}
        onStop={handleRecordingComplete}
      />
    </div>
  );
}

export default InterviewSessionManager;
